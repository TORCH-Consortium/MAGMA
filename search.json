[
  {
    "objectID": "output.html",
    "href": "output.html",
    "title": "MAGMA",
    "section": "",
    "text": "Here we briefly introduce the main outputs from MAGMA pipeline execution, please note that some outputs are optional and depends mainly on specific parameters to be generated.",
    "crumbs": [
      "Output"
    ]
  },
  {
    "objectID": "output.html#qc-statistics-directory",
    "href": "output.html#qc-statistics-directory",
    "title": "MAGMA",
    "section": "QC Statistics Directory",
    "text": "QC Statistics Directory\nIn this directory you will find files related to the quality control carried out by the MAGMA pipeline. The structure is as follows:\n/path/to/results_dir/QC_statistics\n├── cohort\n|   └── fastq_validation\n│   └── multiqc\n│       └── multiqc_data\n└── per_sample\n    ├── coverage\n    ├── fastqc\n    └── mapping\n\ncohort\nHere you will find the joint.merged_cohort_stats.tsv which contains the QC statistics for all samples in the samplesheet and allows users to determine why certain samples failed to be incorporated in the cohort analysis steps\nIn addition, you’ll find the cohort-level MultiQC report generated by per_sample/fastqc analysis and the fastq validation report in json format.\n\nUnderstanding the joint.merged_cohort_stats.tsv file\nTo accurately interpret the joint.merged_cohort_stats.tsv file and assess the quality of each sample analysis, we recommend that users consult the following table, which summarizes all relevant parameters.\n\n\n\n\n\n\n\nParameter\nMeaning\n\n\n\n\nSAMPLE\nIdentifier of the sample being analyzed.\n\n\nAVG_INSERT_SIZE\nAverage size (in base pairs) of the DNA fragment between paired-end reads.\n\n\nMAPPED_PERCENTAGE\nPercentage of reads successfully aligned to the reference genome.\n\n\nRAW_TOTAL_SEQS\nTotal number of raw reads sequenced, before any filtering or trimming.\n\n\nAVERAGE_BASE_QUALITY\nAverage Phred quality score of bases across all reads.\n\n\nMEAN_COVERAGE\nAverage number of times each base of the reference is covered by aligned reads.\n\n\nSD_COVERAGE\nStandard deviation of the per-base coverage; indicates variation in coverage.\n\n\nMEDIAN_COVERAGE\nMedian coverage per base across the reference; less sensitive to outliers than the mean.\n\n\nMAD_COVERAGE\nMedian Absolute Deviation of coverage; measures the variability around the median.\n\n\nPCT_EXC_ADAPTER\nPercentage of bases or reads excluded due to presence of adapter sequences.\n\n\nPCT_EXC_MAPQ\nPercentage of bases or reads excluded due to low mapping quality (MAPQ).\n\n\nPCT_EXC_DUPE\nPercentage of bases or reads marked as duplicates.\n\n\nPCT_EXC_UNPAIRED\nPercentage of reads excluded because they are unpaired in paired-end data.\n\n\nPCT_EXC_BASEQ\nPercentage of bases excluded due to low base quality.\n\n\nPCT_EXC_OVERLAP\nPercentage of bases excluded due to overlapping paired-end reads.\n\n\nPCT_EXC_CAPPED\nPercentage of bases excluded because they exceed the target regions.\n\n\nPCT_EXC_TOTAL\nTotal percentage of excluded bases across all categories.\n\n\nPCT_1X\nPercentage of target bases covered by at least 1 read.\n\n\nPCT_5X\nPercentage of target bases covered by at least 5 reads.\n\n\nPCT_10X\nPercentage of target bases covered by at least 10 reads.\n\n\nPCT_30X\nPercentage of target bases covered by at least 30 reads.\n\n\nPCT_50X\nPercentage of target bases covered by at least 50 reads.\n\n\nPCT_100X\nPercentage of target bases covered by at least 100 reads.\n\n\nLINEAGES FREQUENCIES\nRelative abundance of different detected lineages.\n\n\nMAPPED_NTM_FRACTION_16S\nFraction of 16S reads aligned to non-tuberculous mycobacteria (NTM).\n\n\nMAPPED_NTM_FRACTION_16S_THRESHOLD_MET\nWhether the mapped NTM fraction in 16S exceeded the defined threshold (Boolean).\n\n\nCOVERAGE_THRESHOLD_MET\nWhether the sample met the minimum average coverage requirement (Boolean).\n\n\nBREADTH_OF_COVERAGE_THRESHOLD_MET\nWhether the required genome breadth was achieved (Boolean).\n\n\nRELABUNDANCE_THRESHOLD_MET\nWhether the relative abundance of target organism exceeded the required threshold (Boolean).\n\n\nALL_THRESHOLDS_MET\nBoolean indicating whether all quality and detection thresholds were met.\n\n\n\nThe interpretation of median (middle value) or mean (average) coverage depth should be guided by the following categorization\n\n\n\n\n\n\n\nCoverage Depth\nInterpretation\n\n\n\n\n≥ 50X\nA genome is analysable; nothing should be missed\n\n\n≥ 20X to &lt; 50X\nA genome is analysable with nearly all minor variants detected\n\n\n≥ 10X to &lt; 20X\nA genome is analysable, but some minor variants may not be detected\n\n\n≥ 5X to &lt; 10X\nA genome is analysable, but some variants may not be detected\n\n\n&lt; 5X\nA sample is not analysable\n\n\n\n\n\n\nper_sample/coverage\nContains the GATK WGSMetrics outputs for each of the samples in the samplesheet\n\n\nper_sample/mapping\n\nContains the FlagStat and samtools stats for each of the samples in the samplesheet",
    "crumbs": [
      "Output"
    ]
  },
  {
    "objectID": "output.html#analysis-directory",
    "href": "output.html#analysis-directory",
    "title": "MAGMA",
    "section": "Analysis Directory",
    "text": "Analysis Directory\n/path/to/results_dir/analysis\n├── cluster_analysis\n├── drug_resistance\n├── non-tuberculous_mycobacteria\n├── phylogeny\n├── spotyping\n└── snp_distances\n\nCluster Analysis\n\n\nContains files related to clustering based on 5SNP and 12SNP cutoffs and inclunding and excluding complex regions .figtree files: These can be imported directly into Figtree for visualisation\n\n\nDrug Resistance\n\nOrganised based on the different types of variants as well as combined results:\n/path/to/results_dir/analysis/drug_resistance\n├── combined_resistance_summaries\n├── combined_resistance_summaries_mixed_infection_samples\n├── major_variants_xbs\n├── minor_variants_lofreq\n├── structural_variants_delly\n└── tbprofiler_fastq\nEach of the directories containing results related to the different variants (major | minor | structural) have text files that can be used to annotate the .treefiles produced by MAGMA in iToL (https://itol.embl.de)\nThe combined resistance results file contains a per-sample drug resistance summary based on the WHO Catalogue of Mtb mutations (https://www.who.int/publications/i/item/9789240082410)\nMAGMA also notes the presence of all variants in in tier 1 and tier 2 drug resistance genes.\nMAGMA will generated mixed infection reports and also optionally run tbprofiler from the fastq files for comparison purposes.\n\nNon-Tuberculous Mycobacteria (NTM)\n\nContains a brief report of NTM presence on the submitted samples, in cohort and per_sample structure.\n\nPhylogeny\n\nContains the outputs of the IQTree phylogenetic tree construction.\n\n:memo: By default we recommend that you use the ExDRIncComplex files as MAGMA was optimized to be able to accurately call positions on the edges of complex regions in the Mtb genome\n\n\nSNP distances\n\nContains the SNP distance tables in tsv format.\n\n:memo: By default we recommend that you use the ExDRIncComplex files as MAGMA was optimized to be able to accurately call positions on the edges of complex regions in the Mtb genome\n\n\nSpotyping\n\nContains a spoligotyping pattern prediction using SpoTyping.",
    "crumbs": [
      "Output"
    ]
  },
  {
    "objectID": "output.html#vcf_files-directory",
    "href": "output.html#vcf_files-directory",
    "title": "MAGMA",
    "section": "vcf_files Directory",
    "text": "vcf_files Directory\n/path/to/results_dir/vcf_files\n├── cohort\n│   ├── combined_variant_files\n│   ├── minor_variants\n│   ├── multiple_alignment_files\n│   ├── raw_variant_files\n│   ├── snp_variant_files\n│   └── structural_variants\n└── per_sample\n    ├── minor_variants\n    ├── raw_variant_files\n    └── structural_variants\n\nCombined variant files\n\n\nContains the cohort gvcfs based on major variants detected by the MAGMA pipeline\n\n\nMinor variants\n\n\nMerged vcfs of all samples, generated by LoFreq\n\n\nMultiple alignment files\n\n\nFASTA files for the generation of phylogenetic trees by IQTree\n\n\nRaw variant files\n\n\nUnfiltered indel and SNPs detected by the MAGMA pipeline\n\n\nSNP variant files\n\n\nFiltered SNPs detected by the MAGMA pipeline\n\n\nStructural variant files\n\n\nUnfiltered structural variants detected by the MAGMA pipeline",
    "crumbs": [
      "Output"
    ]
  },
  {
    "objectID": "output.html#libraries-directory",
    "href": "output.html#libraries-directory",
    "title": "MAGMA",
    "section": "Libraries Directory",
    "text": "Libraries Directory\n\nContains files related to FASTQ validation and FASTQC analysis",
    "crumbs": [
      "Output"
    ]
  },
  {
    "objectID": "output.html#samples-directory",
    "href": "output.html#samples-directory",
    "title": "MAGMA",
    "section": "Samples Directory",
    "text": "Samples Directory\n\nContains vcf files for major|minor|structural variants for each individual samples",
    "crumbs": [
      "Output"
    ]
  },
  {
    "objectID": "customizable-parameters.html",
    "href": "customizable-parameters.html",
    "title": "MAGMA Customizable Parameters",
    "section": "",
    "text": "This document provides an overview of the customizable parameters for the MAGMA pipeline. Each parameter is listed with its default value, description.\n\n💡 Hint: you may check a full parameters reference file.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nDefault Value\nDescription\n\n\n\n\ninput_samplesheet\n\"samplesheet.magma.csv\"\nThe input CSV file containing sample information. The study ID cannot start with XBS_REF_.\n\n\n\n\n💡 Hint: The samplesheet should include the fields [Sample, R1, R2]. Optionally, you can add [study, library, attempt, flowcell, lane, index_sequence].\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nDefault Value\nDescription\n\n\n\n\noutdir\n\"magma-results\"\nThe directory where all output files will be written.\n\n\nvcf_name\n\"joint\"\nThe name of the output folder for results. Used to derive JOINT_NAME.\n\n\n\n\n💡 Note: The vcf_name parameter is critical for naming conventions in downstream processes.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nDefault Value\nDescription\n\n\n\n\nuse_ref_gvcf\ntrue\nWhether to use a reference GVCF file to include additional samples.\n\n\nref_gvcf\n\"${projectDir}/resources/ref_gvcfs/LineagesAndOutgroupV2.g.vcf.gz\"\nPath to the reference GVCF file.\n\n\nref_gvcf_tbi\n\"${projectDir}/resources/ref_gvcfs/LineagesAndOutgroupV2.g.vcf.gz.tbi\"\nPath to the index file for the reference GVCF.\n\n\n\n\n💡 Hint: Use this feature if your dataset has low genetic diversity (e.g., clonal or fewer than 20 samples).\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nDefault Value\nDescription\n\n\n\n\ncutoff_median_coverage\n10\nThe minimal median coverage required to process the sample.\n\n\ncutoff_breadth_of_coverage\n0.90\nThe minimal breadth of coverage required to process the sample.\n\n\ncutoff_rel_abundance\n0.70\nThe minimal relative abundance of the majority strain required to process the sample.\n\n\ncutoff_ntm_fraction\n0.20\nThe maximum fraction of NTM DNA allowed to process the sample.\n\n\n\n\n⚠️ Attention: Ensure these values are adjusted based on the quality of your input data to avoid processing errors.\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nDefault Value\nDescription\n\n\n\n\nonly_validate_fastqs\nfalse\nSet to true to only validate input FASTQs and check their FASTQC reports.\n\n\nskip_merge_analysis\nfalse\nSkip the final merge analysis step.\n\n\nskip_variant_recalibration\nfalse\nSkip variant quality score recalibration (VQSR).\n\n\nskip_base_recalibration\ntrue\nSkip base quality score recalibration (BQSR). Not suitable for low-coverage Mtb genomes.\n\n\nskip_minor_variants_gatk\ntrue\nSkip minor variants detection with GATK. LoFreq is recommended for most purposes.\n\n\nskip_phylogeny_and_clustering\nfalse\nDisable downstream phylogenetic analysis of merged GVCF.\n\n\nskip_complex_regions\nfalse\nDisable downstream complex region analysis of merged GVCF.\n\n\nskip_ntmprofiler\nfalse\nDisable execution of ntmprofiler on FASTQ files.\n\n\nskip_tbprofiler_fastq\ntrue\nDisable tbprofiler analysis on FASTQ files.\n\n\nskip_spotyping\nfalse\nDisable spoligotyping analysis.\n\n\n\n\n💡 Hint: Use these flags to customize the pipeline execution based on your specific requirements.\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nDefault Value\nDescription\n\n\n\n\nref_fasta_basename\n\"NC-000962-3-H37Rv\"\nBasename of the reference FASTA file.\n\n\nref_fasta_dir\n\"${projectDir}/resources/genome\"\nDirectory containing the reference FASTA file.\n\n\nref_fasta\n\"${params.ref_fasta_dir}/${params.ref_fasta_basename}.fa\"\nFull path to the reference FASTA file.\n\n\nref_fasta_dict\n\"${params.ref_fasta_dir}/${params.ref_fasta_basename}.dict\"\nPath to the reference FASTA dictionary file.\n\n\nref_fasta_gb\n\"${params.ref_fasta_dir}/${params.ref_fasta_basename}.gb\"\nPath to the reference GenBank file.\n\n\n\n\n⚠️ Warning: It is recommended to use the provided reference files to ensure compatibility with the pipeline.",
    "crumbs": [
      "Customizable Parameters"
    ]
  },
  {
    "objectID": "customizable-parameters.html#common-parameters",
    "href": "customizable-parameters.html#common-parameters",
    "title": "MAGMA Customizable Parameters",
    "section": "",
    "text": "Parameter\nDefault Value\nDescription\n\n\n\n\ninput_samplesheet\n\"samplesheet.magma.csv\"\nThe input CSV file containing sample information. The study ID cannot start with XBS_REF_.\n\n\n\n\n💡 Hint: The samplesheet should include the fields [Sample, R1, R2]. Optionally, you can add [study, library, attempt, flowcell, lane, index_sequence].\n\n\n\n\n\n\n\n\n\n\n\n\n\nParameter\nDefault Value\nDescription\n\n\n\n\noutdir\n\"magma-results\"\nThe directory where all output files will be written.\n\n\nvcf_name\n\"joint\"\nThe name of the output folder for results. Used to derive JOINT_NAME.\n\n\n\n\n💡 Note: The vcf_name parameter is critical for naming conventions in downstream processes.",
    "crumbs": [
      "Customizable Parameters"
    ]
  },
  {
    "objectID": "customizable-parameters.html#additional-samples-addition",
    "href": "customizable-parameters.html#additional-samples-addition",
    "title": "MAGMA Customizable Parameters",
    "section": "",
    "text": "Parameter\nDefault Value\nDescription\n\n\n\n\nuse_ref_gvcf\ntrue\nWhether to use a reference GVCF file to include additional samples.\n\n\nref_gvcf\n\"${projectDir}/resources/ref_gvcfs/LineagesAndOutgroupV2.g.vcf.gz\"\nPath to the reference GVCF file.\n\n\nref_gvcf_tbi\n\"${projectDir}/resources/ref_gvcfs/LineagesAndOutgroupV2.g.vcf.gz.tbi\"\nPath to the index file for the reference GVCF.\n\n\n\n\n💡 Hint: Use this feature if your dataset has low genetic diversity (e.g., clonal or fewer than 20 samples).",
    "crumbs": [
      "Customizable Parameters"
    ]
  },
  {
    "objectID": "customizable-parameters.html#quality-control-parameters",
    "href": "customizable-parameters.html#quality-control-parameters",
    "title": "MAGMA Customizable Parameters",
    "section": "",
    "text": "Parameter\nDefault Value\nDescription\n\n\n\n\ncutoff_median_coverage\n10\nThe minimal median coverage required to process the sample.\n\n\ncutoff_breadth_of_coverage\n0.90\nThe minimal breadth of coverage required to process the sample.\n\n\ncutoff_rel_abundance\n0.70\nThe minimal relative abundance of the majority strain required to process the sample.\n\n\ncutoff_ntm_fraction\n0.20\nThe maximum fraction of NTM DNA allowed to process the sample.\n\n\n\n\n⚠️ Attention: Ensure these values are adjusted based on the quality of your input data to avoid processing errors.",
    "crumbs": [
      "Customizable Parameters"
    ]
  },
  {
    "objectID": "customizable-parameters.html#skipping-pipeline-steps",
    "href": "customizable-parameters.html#skipping-pipeline-steps",
    "title": "MAGMA Customizable Parameters",
    "section": "",
    "text": "Parameter\nDefault Value\nDescription\n\n\n\n\nonly_validate_fastqs\nfalse\nSet to true to only validate input FASTQs and check their FASTQC reports.\n\n\nskip_merge_analysis\nfalse\nSkip the final merge analysis step.\n\n\nskip_variant_recalibration\nfalse\nSkip variant quality score recalibration (VQSR).\n\n\nskip_base_recalibration\ntrue\nSkip base quality score recalibration (BQSR). Not suitable for low-coverage Mtb genomes.\n\n\nskip_minor_variants_gatk\ntrue\nSkip minor variants detection with GATK. LoFreq is recommended for most purposes.\n\n\nskip_phylogeny_and_clustering\nfalse\nDisable downstream phylogenetic analysis of merged GVCF.\n\n\nskip_complex_regions\nfalse\nDisable downstream complex region analysis of merged GVCF.\n\n\nskip_ntmprofiler\nfalse\nDisable execution of ntmprofiler on FASTQ files.\n\n\nskip_tbprofiler_fastq\ntrue\nDisable tbprofiler analysis on FASTQ files.\n\n\nskip_spotyping\nfalse\nDisable spoligotyping analysis.\n\n\n\n\n💡 Hint: Use these flags to customize the pipeline execution based on your specific requirements.",
    "crumbs": [
      "Customizable Parameters"
    ]
  },
  {
    "objectID": "customizable-parameters.html#reference-files",
    "href": "customizable-parameters.html#reference-files",
    "title": "MAGMA Customizable Parameters",
    "section": "",
    "text": "Parameter\nDefault Value\nDescription\n\n\n\n\nref_fasta_basename\n\"NC-000962-3-H37Rv\"\nBasename of the reference FASTA file.\n\n\nref_fasta_dir\n\"${projectDir}/resources/genome\"\nDirectory containing the reference FASTA file.\n\n\nref_fasta\n\"${params.ref_fasta_dir}/${params.ref_fasta_basename}.fa\"\nFull path to the reference FASTA file.\n\n\nref_fasta_dict\n\"${params.ref_fasta_dir}/${params.ref_fasta_basename}.dict\"\nPath to the reference FASTA dictionary file.\n\n\nref_fasta_gb\n\"${params.ref_fasta_dir}/${params.ref_fasta_basename}.gb\"\nPath to the reference GenBank file.\n\n\n\n\n⚠️ Warning: It is recommended to use the provided reference files to ensure compatibility with the pipeline.",
    "crumbs": [
      "Customizable Parameters"
    ]
  },
  {
    "objectID": "usage.html",
    "href": "usage.html",
    "title": "About",
    "section": "",
    "text": "MAGMA (Maximum Accessible Genome for Mtb Analysis) is a pipeline for comprehensive genomic analyses of Mycobacterium tuberculosis with a focus on clinical decision making as well as research.\n\n\n\nPrerequisites\nCustomization\nCitation",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#go-to",
    "href": "usage.html#go-to",
    "title": "About",
    "section": "",
    "text": "Prerequisites\nCustomization\nCitation",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#prerequisites",
    "href": "usage.html#prerequisites",
    "title": "About",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nNextflow\n\ngit : The version control in the pipeline.\nJava-11 or Java-17 LTS release (preferred)\n\n\n:warning: Check java version!: The java version should NOT be an internal jdk release! You can check the release via java --version Notice the LTS next to OpenJDK line.\n\n\n$ java -version\nopenjdk version \"17.0.7\" 2023-04-18 LTS\nOpenJDK Runtime Environment (build 17.0.7+7-LTS)\nOpenJDK 64-Bit Server VM (build 17.0.7+7-LTS, mixed mode, sharing)\n\nDownload Nextflow\n\n$ curl -s https://get.nextflow.io | bash\n\nMake Nextflow executable\n\n$ chmod +x nextflow\n\nAdd nextflow to your path (for example /usr/local/bin/)\n\n$ mv nextflow /usr/local/bin\n\nSanity check for nextflow installation\n\n$ nextflow info\n\n  Version: 23.04.1 build 5866\n  Created: 15-04-2023 06:51 UTC (08:51 SAST)\n  System: Mac OS X 12.6.5\n  Runtime: Groovy 3.0.16 on OpenJDK 64-Bit Server VM 17.0.7+7-LTS\n  Encoding: UTF-8 (UTF-8)\n\n\n:heavy_check_mark: With this you’re all set with Nextflow. Next we shall do a sanity-check for the pipeline setup.:",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#pipeline-setup-sanity-check",
    "href": "usage.html#pipeline-setup-sanity-check",
    "title": "About",
    "section": "Pipeline setup sanity check",
    "text": "Pipeline setup sanity check\nWe provide the test profile, which can be used to test the pipeline as it will\n\nDownload 3 publicly available samples from the MAGMA publication https://doi.org/10.1371/journal.pcbi.1011648\nSave you the trouble of settings up a samplesheet.csv with your own samples\nSave you the trouble of preparing a parameters.yaml file for the analysis\n\nYou can initiate the test as shown below, assuming you will run this on a machine with low resources, we suggest you add laptop as well.\nnextflow run 'https://github.com/TORCH-Consortium/MAGMA' \\\n         -profile test,docker,laptop \\\n         -r v2.2.0\n\n:warning: Run in background!: You might want to run the test in background, using screen or tmux.",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#samplesheet",
    "href": "usage.html#samplesheet",
    "title": "About",
    "section": "Samplesheet",
    "text": "Samplesheet\nA dummy samplesheet is provided here\nThe minimal samplesheet structure should have the following fields.\nSample,R1,R2\nS0001,/full_path_to_directory_of_fastq_files/S0001_01_R1.fastq.gz,full_path_to_directory_of_fastq_files/S0001_01_R1.fastq.gz\nS0002,/full_path_to_directory_of_fastq_files/S0002_01_R1.fastq.gz,full_path_to_directory_of_fastq_files/S0002_01_R2.fastq.gz\nS0003,/full_path_to_directory_of_fastq_files/S0003_01_R1.fastq.gz,\nIf you have the metadata from sequencing instrument, you can specify further information in the samplesheet\nStudy,Sample,Library,Attempt,R1,R2,Flowcell,Lane,Index Sequence\nStudy_Name,S0001,1,1,full_path_to_directory_of_fastq_files/S0001_01_R1.fastq.gz,full_path_to_directory_of_fastq_files/S0001_01_R1.fastq.gz,1,1,1\nStudy_Name,S0002,1,1,full_path_to_directory_of_fastq_files/S0002_01_R1.fastq.gz,full_path_to_directory_of_fastq_files/S0002_01_R2.fastq.gz,1,1,1\nStudy_Name,S0003,1,1,full_path_to_directory_of_fastq_files/S0003_01_R1.fastq.gz,full_path_to_directory_of_fastq_files/S0003_01_R2.fastq.gz,1,1,1\nStudy_Name,S0004,1,1,full_path_to_directory_of_fastq_files/S0004_01_R1.fastq.gz,full_path_to_directory_of_fastq_files/S0004_01_R2.fastq.gz,1,1,1\nHere’s a formatted version of the CSV above, including all optional fields\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudy\nSample\nLibrary\nAttempt\nR1\nR2\nFlowcell\nLane\nIndex Sequence\n\n\n\n\nStudy_Name\nS0001\n1\n1\nfull_path_to_directory_of_fastq_files/S0001_01_R1.fastq.gz\nfull_path_to_directory_of_fastq_files/S0001_01_R1.fastq.gz\n1\n1\n1\n\n\nStudy_Name\nS0002\n1\n1\nfull_path_to_directory_of_fastq_files/S0002_01_R1.fastq.gz\nfull_path_to_directory_of_fastq_files/S0002_01_R2.fastq.gz\n1\n1\n1\n\n\nStudy_Name\nS0003\n1\n1\nfull_path_to_directory_of_fastq_files/S0003_01_R1.fastq.gz\nfull_path_to_directory_of_fastq_files/S0003_01_R2.fastq.gz\n1\n1\n1\n\n\nStudy_Name\nS0004\n1\n1\nfull_path_to_directory_of_fastq_files/S0004_01_R1.fastq.gz\nfull_path_to_directory_of_fastq_files/S0004_01_R2.fastq.gz\n1\n1\n1",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#customization",
    "href": "usage.html#customization",
    "title": "About",
    "section": "Customization",
    "text": "Customization\n\nNote We are currently working on the transition to nf-core standard (see https://github.com/TORCH-Consortium/MAGMA/issues/188), which would add standardized configurations and pipeline structure to benefit from the nf-core nf-core/modules and nf-core/configs projects.\n\nThe pipeline parameters are distinct from Nextflow parameters, and therefore it is recommended that they are provided using a yml (or yaml) file as shown below\n\n# Sample contents of my_parameters_1.yml file\n\ninput_samplesheet: /path/to/your_samplesheet.csv\nonly_validate_fastqs: true\nWhen running the pipeline, use profiles to ensure smooth execution on your computing system. The two types of profiles employed by the pipeline are: execution environment + memory/computing requirements\nExecution environment profiles:\n\nconda_local\ndocker\npodman\n\nMemory/computing profiles:\n\npbs (good for high performance computing clusters)\nserver (good for local servers)\nlow_memory (this can be run on a laptop, even limited to 8 cores and 8 GB of RAM)\n\n\nAdvanced Users The MAGMA pipeline has default parameters related to minimum QC thresholds that must be reached for samples to be included in the cohort analysis. These default parameters are listed in default_params.config. Users wishing to adjust these parameters should specify these adjustments in the params.yml file supplied when launching the pipeline. An example of adjusted parameters is shown below: Note The -profile mechanism is used to enable infrastructure specific settings of the pipeline. The example below, assumes you are using conda based setup.\n\nWhich could be provided to the pipeline using -params-file parameter as shown below\nnextflow run 'https://github.com/TORCH-Consortium/MAGMA' \\\n         -profile docker,server \\\n         -r v2.2.0 \\\n         -params-file  my_parameters_1.yml",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#running-magma-using-nextflow-tower",
    "href": "usage.html#running-magma-using-nextflow-tower",
    "title": "About",
    "section": "Running MAGMA using Nextflow Tower",
    "text": "Running MAGMA using Nextflow Tower\nYou can also use Seqera Platform (aka Nextflow Tower) to run the pipeline on any of the supported cloud platforms and monitoring the pipeline execution.\nPlease refer the Tower docs for further information.",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#running-magma-using-conda",
    "href": "usage.html#running-magma-using-conda",
    "title": "About",
    "section": "Running MAGMA using conda",
    "text": "Running MAGMA using conda\n\n:warning::warning::warning: We discourage running MAGMA via conda, it is prone to challenging-to-reproduce errors\n\nYou can run the pipeline using Conda, Mamba or Micromamba package managers to install all the prerequisite softwares from popular repositories such as bioconda and conda-forge.\n\n:information_source: Conda environments and cheatsheet:  You can find out the location of conda environments using conda env list. Here’s a useful cheatsheet for conda operations.\n\nYou can use the conda based setup for the pipeline for running MAGMA - On a local linux machine(e.g. your laptop or a university server) - On an HPC cluster (e.g. SLURM, PBS) in case you don’t have access to container systems like Singularity, Podman or Docker\nAll the requisite softwares have been provided as a conda recipe (i.e. yml files) - magma-env-1.yml - magma-env-2.yml\nThese files can be downloaded using the following commands\nwget https://raw.githubusercontent.com/TORCH-Consortium/MAGMA/master/conda_envs/magma-env-2.yml\nwget https://raw.githubusercontent.com/TORCH-Consortium/MAGMA/master/conda_envs/magma-env-1.yml\n\nThe conda environments are expected by the conda_local profile of the pipeline, it is recommended that it should be created prior to the use of the pipeline, using the following commands. Note that if you have mamba (or micromamba) available you can rely upon that instead of conda.\n$ conda env create -n magma-env-1 --file magma-env-1.yml\n$ conda env create -n magma-env-2 --file magma-env-2.yml\n$ conda env create -n magma-tbprofiler-env --file magma-tbprofiler-env.yaml\n$ conda env create -n magma-ntmprofiler-env --file magma-ntmprofiler-env.yaml\nOptionally, you can run bash ./conda/setup_conda_envs.sh to build all the necessary conda environments.\nOnce the environments are created, you can make use of the pipeline parameter conda_envs_location to inform the pipeline of the names and location of the conda envs.\nNext, you need to load the WHO Resistance Catalog within tb-profiler; basically the instructions, which are used to build the necessary containers.\n\nDownload magma_resistance_db_who_v1.zip and unzip it\n\nwget https://github.com/TORCH-Consortium/MAGMA/files/14559680/resistance_db_who_v1.zip\n\nunzip resistance_db_who\n\n\nActivate magma-env-1, which has tb-profiler\n\nconda activate magma-env-1\n\n\nMove inside that folder and use tb-profiler load_library functionality to load the database\n\n\ncd resistance_db_who\n\ntb-profiler load_library ./resistance_db_who\n\nSuccess, would look like this",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#running-magma-using-docker",
    "href": "usage.html#running-magma-using-docker",
    "title": "About",
    "section": "Running MAGMA using docker",
    "text": "Running MAGMA using docker\n\n:heavy_check_mark::heavy_check_mark::heavy_check_mark:This is the recommended execution strategy\n\nWe provide two docker containers with the pipeline so that you could just download and run the pipeline with them. There is NO need to create any docker containers, just download and enable the docker profile.\n\n🚧 Container build script: The script used to build these containers is provided here.\n\nAlthough, you don’t need to pull the containers manually, but should you need to, you could use the following commands to pull the pre-built and provided containers\ndocker pull ghcr.io/torch-consortium/magma/magma-container-1:1.1.1\n\ndocker pull ghcr.io/torch-consortium/magma/magma-container-2:1.1.1\n\n:memo: Have singularity or podman instead?:  If you do have access to Singularity or Podman, then owing to their compatibility with Docker, you can still use the provided docker containers.\n\nHere’s the command which should be used\nnextflow run 'https://github.com/torch-consortium/magma' \\\n         -params-file my_parameters_2.yml \\\n         -profile docker,pbs \\\n         -r v1.1.1\n\n:bulb: Hint:  You could use -r option of Nextflow for working with any specific version/branch of the pipeline.",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#running-magma-on-hpc-and-cloud-executors",
    "href": "usage.html#running-magma-on-hpc-and-cloud-executors",
    "title": "About",
    "section": "Running MAGMA on HPC and cloud executors",
    "text": "Running MAGMA on HPC and cloud executors\n\nHPC based execution for MAGMA, please refer this doc.\nCloud batch (AWS/Google/Azure) based execution for MAGMA, please refer this doc",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#magma-samplesheets",
    "href": "usage.html#magma-samplesheets",
    "title": "About",
    "section": "MAGMA samplesheets",
    "text": "MAGMA samplesheets\nIn order to run the MAGMA pipeline, you must provide a samplesheet as input. The structure of the samplesheet should be that located in samplesheet\n\n:warning: Make sure to use full paths!!!:\n\n\nLibrary\n\nCertain samples may have had multiple libraries prepared.\nThis row allows the pipeline to distinguish between\ndifferent libraries of the same sample.\n\nAttempt\n\nCertain libraries may need to be sequenced multiple times.\nThis row allows the pipeline to distinguish between\ndifferent attempts of the same library.\n\nFlowcell/Lane/Index Sequence\n\nProviding this information may allow the VQSR filtering step\nto better distinguish between true variants and sequencing\nerrors. Including these is optional, if unknown or irrelevant,\njust fill in with a '1' as shown in example_MAGMA_samplesheet.csv)",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#optional-gvcf-datasets",
    "href": "usage.html#optional-gvcf-datasets",
    "title": "About",
    "section": "(Optional) GVCF datasets",
    "text": "(Optional) GVCF datasets\nWe also provide some reference GVCF files which you could use for specific use-cases.\n\nFor small datasets (20 samples or less), we recommend that you download the EXIT_RIF GVCF files from https://zenodo.org/record/8054182 containing GVCF reference dataset for ~600 samples is provided for augmenting smaller datasets\nFor including Mtb lineages and outgroup (M. canettii) in the phylogenetic tree, you can download the LineagesAndOutgroup files from https://zenodo.org/record/8233518\n\nuse_ref_gvcf = false\nref_gvcf =  \"/path/to/FILE.g.vcf.gz\"\nref_gvcf_tbi =  \"/path/to/FILE.g.vcf.gz.tbi\"\n\n:bulb: Custom GVCF dataset:  For creating a custom GVCF dataset, you can refer the discussion here.",
    "crumbs": [
      "Usage"
    ]
  }
]